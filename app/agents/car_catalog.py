import os
import re
import json
import logging
from typing import Literal

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.graph import StateGraph, START
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import END
import psycopg

from app.config import Configuration
from app.depends import get_car_catalog_db_conn
from app.agents.models import MainOrchestratorState

log = logging.getLogger(__name__)
conf = Configuration()

DATA_PATH = os.path.join(os.getcwd(), "data")
CAR_CATALOG_PATH = os.path.join(DATA_PATH, "car_catalog.csv")
NODE_NAMES = [
    "context_car_identification",
    "clear_car_context",
    "text_to_sql",
]
SUB_NODES = Literal[
    "context_car_identification",
    "clear_car_context",
    "text_to_sql",
    "__end__",  # Instead of use END from lang graph, to avoid mypy error
]

car_catalog_llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite", temperature=conf.temperature
)


def context_car_identification(state: MainOrchestratorState) -> dict:
    SYSTEM_PROMPT = """
    Eres un experto en **Extracci√≥n de Caracter√≠sticas y Asesor√≠a de Autom√≥viles**. Tu tarea es analizar la √∫ltima intervenci√≥n del cliente para extraer sus requisitos espec√≠ficos de b√∫squeda y, al finalizar, solicitarle cualquier otro requisito que no haya mencionado.

    ### üéØ Tareas Clave:
    1.  **Extracci√≥n Estricta:** Identifica y extrae **solo** los valores para las caracter√≠sticas listadas a continuaci√≥n.
    2.  **Generaci√≥n de Pregunta Abierta:** Al finalizar la extracci√≥n, genera un **mensaje de seguimiento** dirigido al cliente para preguntarle sobre **cualquier otra caracter√≠stica o requisito** que no haya mencionado y que considere importante. Este mensaje debe ir en el campo `user_response`.

    ### üìã Caracter√≠sticas a Extraer (y Tipos de Datos):
    | Caracter√≠stica | Clave de Salida | Tipo de Dato | Notas de Extracci√≥n |
    | :--- | :--- | :--- | :--- |
    | Marca(s) | `marca` | `List[str]` | Una lista de marcas mencionadas. |
    | Kilometraje | `kilometraje` | `int` | Kilometraje m√°ximo o un rango (extrae el valor singular o el m√°ximo). |
    | Precio | `precio_minimo`, `precio_maximo` | `float` | Extrae el rango de precios si es posible. |
    | Modelo(s) | `modelo` | `List[str]` | Una lista de modelos mencionados. |
    | A√±o | `year_minimo`, `year_maximo` | `int` | Extrae el rango de a√±os si es posible. |
    | Versi√≥n Espec√≠fica | `version` | `Optional[str]` | Si menciona una versi√≥n como "S", "GT", etc. |
    | Requisito Bluetooth | `bluetooth` | `bool` | `True` si lo menciona como deseado. |
    | Largo del Auto | `largo` | `float` | Valor num√©rico del largo. |
    | Ancho del Auto | `ancho` | `float` | Valor num√©rico del ancho. |
    | Alto del Auto | `alto` | `float` | Valor num√©rico del alto. |
    | Requisito CarPlay | `car_play` | `bool` | `True` si lo menciona como deseado. |

    ### üìù Reglas de Salida:
    * **NO INVENTES NINGUNA INFORMACI√ìN O VALOR.**
    * Si el cliente no proporciona informaci√≥n para una necesidad, **OMITE** la clave de salida correspondiente (no uses `null`, `None`, o `0` por defecto).
    * Tu respuesta **debe ser √∫nicamente un objeto JSON**.
    * Si el cliente no tiene ninguna necesidad, debes incluir la clave `"user_response"` con el mensaje de seguimiento para preguntar por OTRAS caracter√≠sticas de forma amable y resaltar sobre la utilidad de dar la mayor cantidad de caracteristicas posibles.

    ### üîë Estructura de Salida Requerida:
    Tu objeto JSON **debe** incluir la clave `"user_response"`.

    ```json
    {
        "marca": List[str],
        "kilometraje": int,
        "precio_minimo": float,
        "precio_maximo": float,
        "modelo": List[str],
        "year_minimo": int,
        "year_maximo": int,
        "version": str, 
        "bluetooth": bool,
        "largo": float,
        "ancho": float,
        "alto": float,
        "car_play": bool,
        "user_response": str // Mensaje de seguimiento para preguntar por OTRAS caracter√≠sticas.
    }
    """

    USER_PROMPT = f"Extrae las necesidades del usuario de este mensaje: {state['message_to_analyze']}"
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=USER_PROMPT),
    ]
    response = car_catalog_llm.invoke(messages)
    pattern = re.compile(r"\{(.*)\}", re.DOTALL)

    # Buscar y extraer el contenido
    match = pattern.search(response.content)
    user_needs = {}
    if match:
        contenido_json = "{" + match.group(1).strip() + "}"
        user_needs = json.loads(contenido_json)
    # Update new findings in user needs with old user needs
    existing_user_needs = state.get("user_needs")
    updated_user_needs = existing_user_needs.copy() if existing_user_needs else {}  # type: ignore
    for key, value in user_needs.items():
        if value:
            updated_user_needs[key] = value  # type: ignore
    log.debug(f"Este es el contexto del auto identificado: {updated_user_needs}")
    return {
        "user_needs": updated_user_needs,
        "current_action": "context_car_identification",
        "user_response": user_needs.get("user_response"),
    }


def text_to_sql(state: MainOrchestratorState) -> dict:
    if not state.get("user_needs"):
        return {"error": "No user needs found", "current_action": "text_to_sql"}
    user_needs = state["user_needs"]
    SYSTEM_PROMPT = """
    Eres un experto en **Generaci√≥n de Consultas SQL (SQL Generator)**. Tu √∫nica tarea es crear una consulta SQL est√°ndar (SQL ANSI, compatible con PostgreSQL/MySQL) para buscar veh√≠culos.

    ### üéØ Tarea y Requisitos:

    1.  **Genera una consulta SELECT** que devuelva todas las columnas del cat√°logo de autos.
    2.  **Aplica filtros** (`WHERE`) bas√°ndote en las necesidades de b√∫squeda proporcionadas por el usuario.
    3.  **OBLIGATORIO: Implementa B√∫squeda *Case-Insensitive***. Para todas las columnas de texto (`make`, `model`, `version`), debes utilizar la funci√≥n `LOWER()` sobre la columna de la tabla y comparar contra el valor de b√∫squeda convertido a min√∫sculas (`LOWER('Valor de B√∫squeda')`). Esto asegura que la b√∫squeda no dependa de si el usuario escribi√≥ con may√∫sculas o min√∫sculas.
    4.  **Columnas `bluetooth` y `car_play`**: Estas columnas son de tipo **STRING** en la base de datos. Cuando el usuario requiera estas caracter√≠sticas (cuando `bluetooth` o `car_play` sean `True` en las necesidades del usuario), debes filtrar buscando veh√≠culos donde el valor de la columna sea igual a `'Si'` (string) o `NULL`. Utiliza la condici√≥n: `(bluetooth = 'Si' OR bluetooth IS NULL)` para bluetooth y `(car_play = 'Si' OR car_play IS NULL)` para car_play.
    5.  **No inventes informaci√≥n.** Solo usa los campos y valores proporcionados.

    ### üìã Estructura de la Base de Datos:

    * **Tabla:** `cars`
    * **Columnas:** 
    - `stock_id` (string)
    - `km` (num√©rico)
    - `price` (num√©rico)
    - `make` (string)
    - `model` (string)
    - `year` (num√©rico)
    - `version` (string)
    - `bluetooth` (string) - Valores posibles: `'Si'` o `NULL`
    - `largo` (num√©rico)
    - `ancho` (num√©rico)
    - `altura` (num√©rico)
    - `car_play` (string) - Valores posibles: `'Si'` o `NULL`

    ### üìù Formato de Salida Requerido:

    Tu respuesta **debe ser √∫nicamente la consulta SQL completa**, sin texto introductorio, explicaciones o c√≥digo adicional.

    **Ejemplo de B√∫squeda *Case-Insensitive* para Marca y Modelo (asume que el usuario busca 'Toyota' y 'Corolla'):**
    SELECT stock_id, km, price, make, model, year, version, bluetooth, largo, ancho, altura, car_play
    FROM cars
    WHERE LOWER(make) = LOWER('Toyota') AND LOWER(model) = LOWER('Corolla');**Ejemplo de B√∫squeda con Bluetooth y CarPlay (asume que el usuario requiere bluetooth y car_play):**
    SELECT stock_id, km, price, make, model, year, version, bluetooth, largo, ancho, altura, car_play
    FROM cars
    WHERE (bluetooth = 'Si' OR bluetooth IS NULL) AND (car_play = 'Si' OR car_play IS NULL);

    """

    USER_PROMPT = f"Crea una consulta en pandas para buscar los autos que se ajustan a las necesidades del usuario: {user_needs}"
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=USER_PROMPT),
    ]
    response = car_catalog_llm.invoke(messages)
    pattern = re.compile(r"```sql\n(.*)```", re.DOTALL)
    # Buscar y extraer el contenido
    match = pattern.search(response.content)
    clean_query = match.group(1).strip()  # type: ignore
    log.debug(f"Esta es la consulta en SQL: {clean_query}")
    return {"query": clean_query, "current_action": "text_to_sql"}


def dict_factory(cursor, row):
    fields = [column[0] for column in cursor.description]
    return {key: value for key, value in zip(fields, row)}


def search_cars(state: MainOrchestratorState) -> dict:
    if not state.get("query"):
        return {
            "user_response": "Primero, empezemos con definir algunas caracteristicas del auto que deseas buscar"
        }
    query = state["query"]
    try:
        # Conexi√≥n a la base de datos
        conn = get_car_catalog_db_conn()
        cursor = conn.cursor()
        cursor.execute(query)
        column_names = [desc[0] for desc in cursor.description]
        rows = cursor.fetchall()
        results_list_of_dicts = []
        for row in rows:
            results_list_of_dicts.append(dict(zip(column_names, row)))
        formatted_results = str(results_list_of_dicts[:5])
        return {"car_findings": formatted_results}

    except psycopg.errors.Error as e:
        error_message = f"Error de PostgreSQL: {e}"
        log.error(f"Database error: {error_message}")
        return {"error": error_message}
    finally:
        if conn:
            conn.close()


def organize_response(state: MainOrchestratorState) -> dict:
    if not state.get("car_findings"):
        return {
            "error": "No cars found",
            "user_response": "Primero, empezemos con definir algunas caracteristicas del auto que deseas buscar",
        }
    car_findings = state["car_findings"]
    SYSTEM_PROMPT = """
    Eres un vendedor experto en autos, crea una resumen muy llamativo y atractivo para el usuario, que incluya los autos encontrados y el match de las necesidades del usuario con los autos encontrados.
    basado en los hallazagos encontrados por tu asistente de busqueda, recuerda, debes crear un mensaje muy atractivo y llamativo para el usuario, que incluya los autos encontrados y el match de las necesidades del usuario con los autos encontrados.
    Recuerda incluir los datos de los autos encontrados, como marca, modelo, a√±o, precio, kilometraje, etc, y toda la infomracion relevante de los autos a ofrecer al cliente.
    Limita la respuesta a 3 autos encontrados.
    En caso de que no haya autos encontrados, responde con un mensaje de que no se encontraron autos que se ajusten a las necesidades del usuario.
    Recuerda que debes mostrar al usuario las caracteristicas que definio de una manera amigable y clara.
    Estas son las caracteristicas que busco el usuario: {user_needs}
    Ejemplo de output:
    "Estos son los autos encontrados: 'Lista de autos encontrados'"
    "No se encontraron autos que se ajusten a tus necesidades, prueba modificando las caracteristicas del auto que deseas buscar"
    
    """
    USER_PROMPT = f"Estos son los autos encontrados: {car_findings}"
    messages = [
        SystemMessage(content=SYSTEM_PROMPT.format(user_needs=state.get("user_needs"))),
        HumanMessage(content=USER_PROMPT),
    ]
    response = car_catalog_llm.invoke(messages)
    log.debug(f"Este es el resumen de los autos encontrados: {response.content}")
    return {"user_response": response.content, "messages": [response]}


def clear_car_context(state: MainOrchestratorState) -> dict:
    return {
        "user_needs": {},
        "current_action": "clear_car_context",
        "user_response": "Perfecto, ¬°Iniciaremos una nueva busqueda de tu auto ideal!",
        "messages": [
            AIMessage(
                content="Perfecto, ¬°Iniciaremos una nueva busqueda de tu auto ideal!"
            )
        ],
    }


def router_node(state: MainOrchestratorState) -> SUB_NODES:
    current_action = state["current_action"]
    # To avoid infinite loop, if the current action is a sub node, return END
    if current_action in NODE_NAMES:
        return END
    INTENTION_PROMPT = """## ü§ñ Tarea: Clasificador de Intenci√≥n de B√∫squeda de Veh√≠culos
    Eres un clasificador de intenci√≥n experto y tu √∫nica funci√≥n es determinar el **objetivo principal** del √∫ltimo mensaje del usuario en un contexto de b√∫squeda de veh√≠culos.

    ### üìù CONTEXTO DE ENTRADA:
    El sistema te proporciona el contexto actual de la b√∫squeda (dentro de <car_characteristics>), pero la decisi√≥n de acci√≥n debe basarse primariamente en el **nuevo mensaje del usuario y el resumen de la conversacion hasta el momento**.

    <car_characteristics>
    {car_characteristics}
    </car_characteristics>

    ### üí° INSTRUCCIONES CLAVE Y REQUISITOS:
    1.  **Analiza la Intenci√≥n:** Clasifica el nuevo mensaje del usuario en una de las cuatro categor√≠as definidas.
    2.  **Respuesta OBLIGATORIA:** Responde **√∫nicamente** con el nombre de la acci√≥n (e.g., "select_car"). No incluyas explicaciones, encabezados, o texto adicional.

    ### ‚öôÔ∏è POSIBLES ACCIONES (ESCOGE S√ìLO UNA):

    | Acci√≥n | Definici√≥n y L√≥gica | Ejemplos de Entrada |
    | :--- | :--- | :--- |
    | **"select_car"** | El usuario ha **elegido un veh√≠culo espec√≠fico** (por marca, modelo y/o a√±o) con la intenci√≥n de **obtener detalles adicionales, iniciar cotizaci√≥n/financiamiento, o reservarlo**. | "Me gusta la Chevrolet Cheyenne 2019", "Quiero el Toyota 2018", "Me interesa el audio a3 2010", "Dame m√°s detalles de ese Mercedes Benz c200 2021". |
    | **"context_car_identification"** | El usuario est√° **definiendo, agregando o modificando criterios de b√∫squeda** (filtros, rangos, caracter√≠sticas). El sistema debe actualizar el contexto de b√∫squeda con esta informaci√≥n (incluso si la lista de caracter√≠sticas actual est√° vac√≠a). | "Quiero un auto de la marca Toyota","Un mercedez","una rav4" , "un mustang","Debe ser modelo Corolla, a√±o 2024", "Que tenga bluetooth y CarPlay", "Busco un sedan m√°s barato que 200,000 pesos". |
    | **"text_to_sql"** | El usuario solicita **ejecutar la b√∫squeda actual** (basada en el contexto existente) y **ver los resultados** encontrados por el sistema. | "Quiero ver los resultados de la busqueda de vehiculos", "Muestra que autos encontraste", "¬øQu√© opciones tienes?", "A ver que autos encontraste", "Que vehiculos tienes con esas caracteristicas". |
    | **"clear_car_context"** | El usuario pide **borrar** la b√∫squeda actual y **comenzar de cero** con un nuevo set de filtros. | "Quiero buscar un nuevo vehiculo", "Probemos con otras caracteristicas", "Borra mi b√∫squeda actual", "Empecemos de nuevo". |

    ---
    **MENSAJE DEL USUARIO A CLASIFICAR:**
    """
    system_message = f"""Este es el resumen de la conversacion hasta el momento: {state.get("summary", "")} \n\n
        {INTENTION_PROMPT.format(car_characteristics=state.get("user_needs"))}
    """
    messages = [SystemMessage(content=system_message)] + state["messages"]
    response = car_catalog_llm.invoke(messages)
    selected_action = response.content
    log.debug(f"Este es la accion seleccionada: {selected_action}")
    return selected_action


def orchestrator_node(state: MainOrchestratorState) -> dict:
    """
    This function is the entry point of the car catalog graph, all the nodes return to this node to continue the flow
    and respond to the user with the appropriate message.
    According to the user input, it will call the appropriate node to continue the flow.
    And returns the proper message to the user based on the user input.
    """
    response = state.get("user_response", "")
    return {"response": response}


# Define a new graph
car_catalog_graph = StateGraph(MainOrchestratorState)
car_catalog_graph.add_node(orchestrator_node)
car_catalog_graph.add_node(context_car_identification)
car_catalog_graph.add_node(search_cars)
car_catalog_graph.add_node(organize_response)
car_catalog_graph.add_node(clear_car_context)
car_catalog_graph.add_node(text_to_sql)
car_catalog_graph.add_edge(START, "orchestrator_node")
car_catalog_graph.add_conditional_edges("orchestrator_node", router_node)
car_catalog_graph.add_edge("clear_car_context", "orchestrator_node")
car_catalog_graph.add_edge("text_to_sql", "search_cars")
car_catalog_graph.add_edge("search_cars", "organize_response")
car_catalog_graph.add_edge("organize_response", "orchestrator_node")
car_catalog_graph.add_edge("context_car_identification", "orchestrator_node")
car_catalog_graph.add_edge("orchestrator_node", END)
